
  0%|          | 0/901 [00:00<?, ?it/s]
Epoch 1/1:   0%|          | 0/901 [00:01<?, ?it/s]
Epoch 1/1:   0%|          | 0/901 [00:01<?, ?it/s, concept_loss=2.99, lpips_loss=0.107, total_loss=15]
Epoch 1/1:   0%|          | 1/901 [00:01<27:26,  1.83s/it, concept_loss=2.99, lpips_loss=0.107, total_loss=15]
Epoch 1/1:   0%|          | 1/901 [00:02<27:26,  1.83s/it, concept_loss=2.99, lpips_loss=0.107, total_loss=15]
Epoch 1/1:   0%|          | 1/901 [00:02<27:26,  1.83s/it, concept_loss=1.88e+3, lpips_loss=0.476, total_loss=9.41e+3]
Epoch 1/1:   0%|          | 2/901 [00:02<17:26,  1.16s/it, concept_loss=1.88e+3, lpips_loss=0.476, total_loss=9.41e+3]
Epoch 1/1:   0%|          | 2/901 [00:02<17:26,  1.16s/it, concept_loss=1.88e+3, lpips_loss=0.476, total_loss=9.41e+3]
Epoch 1/1:   0%|          | 2/901 [00:03<17:26,  1.16s/it, concept_loss=192, lpips_loss=0.68, total_loss=962]         
Epoch 1/1:   0%|          | 3/901 [00:03<14:11,  1.06it/s, concept_loss=192, lpips_loss=0.68, total_loss=962]
Epoch 1/1:   0%|          | 3/901 [00:03<14:11,  1.06it/s, concept_loss=192, lpips_loss=0.68, total_loss=962]
Epoch 1/1:   0%|          | 3/901 [00:03<14:11,  1.06it/s, concept_loss=164, lpips_loss=0.511, total_loss=819]
Epoch 1/1:   0%|          | 4/901 [00:03<12:42,  1.18it/s, concept_loss=164, lpips_loss=0.511, total_loss=819]
Epoch 1/1:   0%|          | 4/901 [00:04<12:42,  1.18it/s, concept_loss=164, lpips_loss=0.511, total_loss=819]
Epoch 1/1:   0%|          | 4/901 [00:04<12:42,  1.18it/s, concept_loss=2.94, lpips_loss=0.732, total_loss=15.4]
Epoch 1/1:   1%|          | 5/901 [00:04<11:55,  1.25it/s, concept_loss=2.94, lpips_loss=0.732, total_loss=15.4]
Epoch 1/1:   1%|          | 5/901 [00:05<11:55,  1.25it/s, concept_loss=2.94, lpips_loss=0.732, total_loss=15.4]
Epoch 1/1:   1%|          | 5/901 [00:05<11:55,  1.25it/s, concept_loss=62.1, lpips_loss=0.507, total_loss=311] 
Epoch 1/1:   1%|          | 6/901 [00:05<11:22,  1.31it/s, concept_loss=62.1, lpips_loss=0.507, total_loss=311]
Epoch 1/1:   1%|          | 6/901 [00:05<13:26,  1.11it/s, concept_loss=62.1, lpips_loss=0.507, total_loss=311]

Validation:   0%|          | 0/147 [00:00<?, ?it/s]
Validation:   1%|          | 1/147 [00:00<01:20,  1.81it/s]
Validation:   1%|▏         | 2/147 [00:00<01:00,  2.41it/s]
Validation:   2%|▏         | 3/147 [00:01<00:53,  2.68it/s]
Validation:   3%|▎         | 4/147 [00:01<00:50,  2.84it/s]
Validation:   3%|▎         | 5/147 [00:01<00:49,  2.85it/s]
Validation:   4%|▍         | 6/147 [00:02<00:47,  2.94it/s]
Validation:   4%|▍         | 6/147 [00:02<00:53,  2.64it/s]

making attention of type 'vanilla' with 512 in_channels
Working with z of shape (1, 3, 64, 64) = 12288 dimensions.
making attention of type 'vanilla' with 512 in_channels
Restored from /home/seungho/.cache/huggingface/hub/models--stanfordmimi--MedVAE/snapshots/8040c5ccb7a51eff6b4cef513c7f20bd1bda983d/model_weights/vae_4x_3c_2D.ckpt with 0 missing and 0 unexpected keys
Validation Results - Concept Loss: 2.6656, LPIPS Loss: 0.0231, Total Loss: 13.3511
Average AUROC per task: [nan, nan, nan, nan, nan, nan, nan, np.float64(0.6243686868686869), nan, nan, nan]
Average MAE per task: [23.861968994140625, 14.529827117919922]
New best model saved with loss: 13.3511

